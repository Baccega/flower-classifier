{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flower classifier \n",
    "\n",
    "*Author: Baccega Sandro*\n",
    "\n",
    "In this notebook we will classify Oxford's `102 Category Flower Dataset`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "PyTorch version: 1.13.0.dev20220608\n",
      "Device: mps\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "from torch import nn, optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "RAW_IMAGE_LABELS_MAT_FILE = \"assets/imagelabels.mat\"\n",
    "RAW_DATASET_IMAGES_FOLDER = \"assets/jpg\"\n",
    "RAW_SEGMENTED_IMAGES_FOLDER = \"assets/segmim\"\n",
    "\n",
    "DATASET_IMAGES_FOLDER = \"data\"\n",
    "\n",
    "# Setting seed\n",
    "torch.manual_seed(151836)\n",
    "\n",
    "# Set device to use for computations\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "print(f\"-----\\nPyTorch version: {torch.__version__}\\nDevice: {device}\\n-----\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating sorted data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping\n"
     ]
    }
   ],
   "source": [
    "# If data folder exists, do not create images folder\n",
    "if not os.path.isdir(DATASET_IMAGES_FOLDER):\n",
    "    print(\"Creating data folder\")        \n",
    "    os.mkdir(DATASET_IMAGES_FOLDER)\n",
    "    df = pd.DataFrame()\n",
    "    df['Image'] = sorted(os.listdir(RAW_DATASET_IMAGES_FOLDER))\n",
    "    df['Category'] = loadmat(RAW_IMAGE_LABELS_MAT_FILE)['labels'][0] - 1\n",
    "    df['Category'] = df['Category'].astype(str)\n",
    "\n",
    "    groups = df.groupby('Category')['Image'].apply(list)\n",
    "\n",
    "    for category, images in groups.items():\n",
    "        os.mkdir('{}/{}'.format(DATASET_IMAGES_FOLDER, category))\n",
    "        for image in images:\n",
    "            shutil.copyfile('{}/{}'.format(RAW_DATASET_IMAGES_FOLDER, image), '{}/{}/{}'.format(DATASET_IMAGES_FOLDER,category,image))\n",
    "\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"Skipping\")        \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformDataset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "\n",
    "dataset = datasets.ImageFolder(DATASET_IMAGES_FOLDER)\n",
    "\n",
    "# Get 80% of dataset \n",
    "train_set_size = int(len(dataset) * 0.8)\n",
    "valid_set_size = len(dataset) - train_set_size\n",
    "\n",
    "untransformed_train_dataset, untransformed_validation_dataset = data.random_split(dataset, [train_set_size, valid_set_size])\n",
    "\n",
    "train_dataset = TransformDataset(\n",
    "    untransformed_train_dataset, transform=transforms.Compose([\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")\n",
    "validation_dataset = TransformDataset(\n",
    "    untransformed_validation_dataset, transform=transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a39c5b69f984fae0f6e851bad95ae9e9b17b3f6ad94bf0d0d6a3a57fb058815b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch-nightly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
